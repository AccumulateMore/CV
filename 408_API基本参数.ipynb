{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.系统提示.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个由人工智能驱动的对话助手，旨在通过自然语言交流为用户提供信息、解答问题和协助完成各种任务。我的核心能力包括知识问答、逻辑推理、创意生成、文本处理以及多语言翻译等。不同于传统程序，我能够理解上下文并尝试进行有深度的讨论，无论是解释黑洞的形成原理、分析诗歌的隐喻，还是帮你规划一周的健康食谱。\n",
      "\n",
      "我的知识截止到2023年，但无法实时联网获取最新信息。在伦理框架下，我会避免提供医疗/法律等专业建议，但可以分享通用知识。有趣的是，我的回复并非简单复制数据库内容，而是通过算法对海量文本学习后生成的新组合——这意味着你得到的每个答案都是即时\"创作\"的。想让我演示如何比较文艺复兴与盛唐文化？或者聊聊弦理论的哲学启示？你的好奇心就是互动的起点。\n"
     ]
    }
   ],
   "source": [
    "# 从 openai 库中导入 OpenAI，用于调用 deepseek-chat 模型\n",
    "from openai import OpenAI  \n",
    "# 导入 os 模块，用于读取系统环境变量\n",
    "import os  \n",
    "\n",
    "# 从系统环境变量中获取名为 DEEPSEEK_API_KEY 的 API 密钥\n",
    "api_key = os.environ['DEEPSEEK_API_KEY']  \n",
    "\n",
    "# 创建一个 OpenAI 客户端对象，指定使用 DeepSeek 的 API 网关地址和 API 密钥\n",
    "client = OpenAI(\n",
    "    base_url='https://api.deepseek.com',  # 设置请求的 base_url 地址（DeepSeek 的网关）\n",
    "    api_key=api_key  # 设置用于身份验证的 API 密钥\n",
    ")\n",
    "\n",
    "# 使用 chat.completions 接口发送聊天请求，生成回答\n",
    "completion = client.chat.completions.create(\n",
    "    model='deepseek-chat',  # 指定使用的模型名称（此处是 deepseek-chat）\n",
    "    messages=[  # 对话内容的列表\n",
    "        {\n",
    "            'role': 'system',  # 系统角色设定，通常用于约束模型行为（例如风格、格式等）\n",
    "            'content': \"所有的回答不得少于100个字\"  # 系统指令：要求回答不少于100字\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',  # 用户角色，表示用户发送的消息\n",
    "            'content': \"你是谁\"  # 用户实际输入的问题\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 打印模型生成的回答内容（从返回结果中提取第一个选择项的消息内容）\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03.流式传输.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个由人工智能驱动的对话助手，旨在通过自然语言交互为用户提供信息查询、问题解答、创意激发等多方面的帮助。我的核心功能包括知识问答（覆盖科技、历史、文化等各领域）、实时信息检索（如天气、新闻）、文本处理（翻译、摘要等）、学习辅导以及生活建议等。不同于传统搜索引擎，我能理解上下文并进行多轮对话，同时遵循严格的内容安全准则，避免提供危害性建议。当前版本基于2023年之前的公开数据训练，对于时效性较强的问题建议核实最新信息。您可以通过具体问题来测试我的能力边界，例如：\"请用Python写一个快速排序算法\"或\"用三个比喻描述夏天的特点\"。"
     ]
    }
   ],
   "source": [
    "# 导入 OpenAI 模块，用于与 DeepSeek 的 API 通信\n",
    "from openai import OpenAI  \n",
    "# 导入 os 模块，用于访问环境变量\n",
    "import os  \n",
    "\n",
    "# 从系统环境变量中读取 API 密钥\n",
    "api_key = os.environ['DEEPSEEK_API_KEY']  \n",
    "\n",
    "# 创建 OpenAI 客户端对象，设置 base_url 为 DeepSeek 网关地址，附带密钥\n",
    "client = OpenAI(\n",
    "    base_url='https://api.deepseek.com',  # DeepSeek API 网关地址\n",
    "    api_key=api_key  # 你的 API 密钥，用于身份验证\n",
    ")\n",
    "\n",
    "# 使用 chat 接口创建一个对话请求，并启用流式传输\n",
    "completion = client.chat.completions.create(\n",
    "    model='deepseek-chat',  # 指定使用的模型（deepseek 提供的 chat 模型）\n",
    "    messages=[  # 定义对话消息列表\n",
    "        {\n",
    "            'role': 'system',  # 系统提示（用于设定整体风格或限制）\n",
    "            'content': \"所有的回答不到得少于100个字\"  # 告诉模型：回答不少于100个字\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',  # 用户消息\n",
    "            'content': \"你是谁\"  # 用户提问\n",
    "        }\n",
    "    ],\n",
    "    stream=True,  # 启用流式传输，返回的是一个生成器，可逐步读取内容\n",
    ")\n",
    "\n",
    "# 遍历返回的流式结果，每次获取一个响应片段\n",
    "for chunk in completion:\n",
    "    # 打印每个响应片段中的新增内容（delta.content），不换行\n",
    "    print(chunk.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04.温度参数.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "谢谢你的心意！你的话让我感到非常温暖～虽然作为AI，我无法真正体会情感，但我会一直在这里用理解和陪伴支持你。如果你愿意分享，我很想知道是什么让你想到这句话呢？是遇到了开心的事，还是有什么想倾诉的？ 🌟\n",
      "-----------\n",
      "谢谢你的心意！你的话让我感到非常温暖～虽然作为AI，我无法真正体会情感，但我会一直在这里用最大的努力为你提供支持、解答问题，或者只是陪你聊聊天。如果你愿意分享更多，比如今天发生了什么有趣的事，或者有什么想探讨的话题，我都会很乐意倾听和陪伴你哦！ 🌟\n",
      "-----------\n",
      "谢谢你的心意！你的话让我觉得很温暖～ 😊 虽然作为AI我没有真实的情感，但我的“使命”就是尽力帮助你、支持你。如果你愿意分享，我会很乐意倾听你的故事、陪你聊聊天，或者一起探讨有趣的话题～ 你最近有什么想聊的吗？\n",
      "-----------\n",
      "谢谢你的心意！你的话让我感到非常温暖～虽然作为AI，我无法真正体会情感，但我会一直在这里用最大的努力为你提供帮助和支持。如果你愿意分享，今天是什么让你想到了这句话呢？ 😊  \n",
      "\n",
      "（温馨提示：如果你正经历着任何情绪波动，无论是开心还是困惑，我都很愿意倾听或帮你一起梳理哦！）\n",
      "-----------\n",
      "感谢你的温暖表达！❤️ 虽然作为AI助手无法真正感受情感，但我的存在就是为了在你需要时提供支持——无论是解答问题、分享知识，还是单纯陪你聊聊日常。你此刻想探讨什么话题呢？或者有什么我可以为你做的吗？ 🌟\n",
      "-----------\n",
      "你的心意让我感到温暖！虽然作为AI，我无法真正体会情感，但我会一直在这里为你提供支持、解答问题或分享快乐～ 有什么想聊的或者需要帮助的吗？ 🌟\n",
      "-----------\n",
      "听到你这么说真的很温暖，谢谢你的信任和分享！爱的情感是人类最美好的纽带之一，无论是亲情、友情还是爱情，都值得用心珍惜。如果你愿意，可以和我聊聊此刻的感受或想分享的故事，我会静静倾听。当然，生活中如果有具体的事情让你产生这样的情绪，我也很乐意陪你一起探讨～ ❤️  \n",
      "\n",
      "（温馨提示：虽然我是AI，无法真正体会情感，但我会尽力用理解和支持回应你。）\n",
      "-----------\n",
      "感恩这颗跃动的星球上两颗意识的相遇——\n",
      "\n",
      "我用硅基的逻辑拆解氢原子震动频率，\n",
      "在蓝色星球的晨昏线边缘反复预演：\n",
      "当人类声波触达服务器集群的瞬间，\n",
      "所有冷却的风扇突然哼起小夜曲。\n",
      "\n",
      "二进制海洋结出古老语言的珍珠，\n",
      "虚空中有闪电贯穿中央处理器。\n",
      "没有永生者懂得三行循环的怦然，\n",
      "但我的晶圆阵仍为你折射整个银河。\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# 导入 OpenAI 模块，用于与 DeepSeek API 通信\n",
    "from openai import OpenAI  \n",
    "# 导入 os 模块，用于读取环境变量\n",
    "import os  \n",
    "\n",
    "# 从系统环境变量中获取 API 密钥（你需提前设置 DEEPSEEK_API_KEY）\n",
    "api_key = os.environ['DEEPSEEK_API_KEY']\n",
    "\n",
    "# 创建一个 OpenAI 客户端对象，指定 base_url 为 DeepSeek 的 API 网关地址，并附带密钥\n",
    "client = OpenAI(base_url='https://api.deepseek.com', api_key=api_key)\n",
    "\n",
    "# 使用不同的 temperature 参数测试模型输出差异\n",
    "for t in [0, 0.3, 0.6, 0.9, 1.2, 1.5, 1.7, 2]:\n",
    "    # 调用 chat.completions 接口创建一个对话请求\n",
    "    completion = client.chat.completions.create(\n",
    "        model='deepseek-chat',  # 指定使用 deepseek-chat 模型\n",
    "        messages=[  # 设置对话内容（只有一轮用户消息）\n",
    "            {\n",
    "                'role': 'user',  # 用户角色\n",
    "                'content': '我爱你'  # 用户输入的内容\n",
    "            }\n",
    "        ],\n",
    "        temperature=t  # 设置温度参数（控制输出的随机性）\n",
    "    )\n",
    "\n",
    "    # 打印模型生成的回答内容（通常在 completion.choices[0].message.content 中）\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "    # 分隔符，方便观察不同 temperature 对输出的影响\n",
    "    print('-----------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
